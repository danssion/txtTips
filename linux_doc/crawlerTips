########## 0.base info ###########
JMX的全称为Java Management Extensions
1）程序端的Instrumentation
2）程序端的JMX agent
3）客户端的Remote Management

JMX agent与Remote Management之间是协议：HTTP/SNMP/RMI/IIOP

########## 1.1 weblogic base ###########
1.Downloader
WebMagic默认使用了Apache HttpClient作为下载工具
2.PageProcessor
PageProcessor负责解析页面，抽取有用信息，以及发现新的链接。
WebMagic使用Jsoup作为HTML解析工具，并基于其开发了解析XPath的工具Xsoup
PageProcessor对于每个站点每个页面都不一样，是需要使用者定制的部分。
3.Scheduler
Scheduler负责管理待抓取的URL，以及一些去重的工作。
WebMagic默认提供了JDK的内存队列来管理URL，并用集合来进行去重。也支持使用Redis进行分布式管理。
除非项目有一些特殊的分布式需求，否则无需自己定制Scheduler。
4.Pipeline
Pipeline负责抽取结果的处理，包括计算、持久化到文件、数据库等。WebMagic默认提供了“输出到控制台”和“保存到文件”两种结果处理方案。
Pipeline定义了结果保存的方式，如果你要保存到指定数据库，则需要编写对应的Pipeline。对于一类需求一般只需编写一个Pipeline。

########## 1.2 weblogic extension ###########
1.webmagic-samples
作者早期编写的一些爬虫的例子。
2.webmagic-scripts
让开发者脱离Java语言，来进行简单、快速的开发。同时强调脚本的共享。
3.webmagic-selenium
WebmMgic与Selenium结合的模块。Selenium是一个模拟浏览器进行页面渲染的工具，WebMagic依赖Selenium进行动态页面的抓取。
4.webmagic-saxon
WebMagic与Saxon结合的模块。
Saxon是一个XPath、XSLT的解析工具，webmagic依赖Saxon来进行XPath2.0语法解析支持。

########## 1.3 weblogic jar ###########
webmagic-core-{version}.jar
webmagic-extension-{version}.jar
  
########## 1.4 weblogic develop env ###########
使用Maven Eclipse插件
mvn eclipse:eclipse
  

########## 2.0 JVM  ###########
JMX的全称为Java Management Extensions.
    
########## 3. allydata crawler ###########
########## 3.1 kafka topic  ###########
./kafka/bin/kafka-topics --zookeeper hd-client:2181/dmp/spider_kafka --list
./bin/kafka-topics.sh --zookeeper hd-client:2181  --delete --topic dmp1

########## 3.1 mvn cmd ###########
mvn clean install -Ptest -D maven.test.skip=true
mvn install -Ptest -DskipTests 


########## 3.2 allydata crawler install order ###########
crawler-commons
  logger
  entity
  curator
  communication
  queue
  datatbase
  manager
  parse/downloader
  selector
  spider
  config-web
  scheduler


########## 3.3 allydata crawler curator ###########
#Curator提供了一套Java类库， 可以更容易的使用ZooKeeper
#Curator是Netflix开源的一套ZooKeeper客户端框架
#功能
封装ZooKeeper client与ZooKeeper server之间的连接处理;
提供了一套Fluent风格的操作API;
提供ZooKeeper各种应用场景(recipe, 比如共享锁服务, 集群领导选举机制)的抽象封装.

#
#组件概览
Recipes           通用ZooKeeper技巧(“recipes”)的实现. 建立在Curator Framework之上
                  <note:Recipe 词典的意思是食谱,配方,美食菜谱,烹饪法， 延伸用法：某项计划或步骤来取得预先给定的结果。
                   在计算机领域没有合适的汉语对应，如果把ZooKeeper看成菜的话，recipe就相当于菜谱， 比如麻婆豆腐， 宫保鸡丁。>
Framework         简化zookeeper使用的高级. 增加了很多建立在zookeeper之上的特性. 管理复杂连接处理和重试操作
Utilities         各种工具类
Client            ZooKeeper本身提供的类的替代者。 负责底层的开销以及一些工具
Errors            Curator怎样来处理错误和异常
Extensions        对curator-recipes的扩展实现，拆分为 curator-:stuck_out_tongue_closed_eyes:iscovery
                    和 curator-:stuck_out_tongue_closed_eyes:iscovery-server提供基于RESTful的Recipes WEB服务. 
                 

Curator把一些其它的Recipe放在单独的Extensions包中， 命名方式就是curator-x-<name>,比如curator-x-discovery， curator-x-rpc

curator-x-discovery:

这是一个服务发现的Recipe
DiscoveryExample提供了增加，删除，显示，注册已有的服务的功能

Curator RPC Proxy（curator-x-rpc）和 Service Discovery Server（curator-x-discovery-server）是为了桥接非Java应用的扩展

########## 3.4 allydata Java NIO ###########
#http://ifeve.com/java-nio-all/
#Java NIO(New IO)是一个可以替代标准Java IO API的IO API（从Java 1.4开始)，Java NIO提供了与标准IO不同的IO工作方式。
1.Java NIO: Channels and Buffers（通道和缓冲区）
2.Java NIO: Non-blocking IO（非阻塞IO）
3.Java NIO: Selectors（选择器）


########## 3.5 allydata Java Netty ###########
#Netty是一个提供异步事件驱动的网络应用框架，用以快速开发高性能、高可靠性的网络服务器和客户端程序
#Netty是一个NIO框架，使用它可以简单快速地开发网络应用程序，比如客户端和服务端的协议。Netty大大简化了网络程序的开发过程比如TCP和UDP的 Socket的开发。
Java BIO ： 同步并阻塞，服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，当然可以通过线程池机制改善。
Java NIO ： 同步非阻塞，服务器实现模式为一个请求一个线程，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。
Java AIO(NIO.2) ： 异步非阻塞，服务器实现模式为一个有效请求一个线程，客户端的I/O请求都是由OS先完成了再通知服务器应用去启动线程进行处理，
  
########## 3.6 allydata Java org.apache.commons.dbutils ###########
#commons-dbutils 是 Apache 组织提供的一个开源 JDBC工具类库，它是对JDBC的简单封装，学习成本极低，并且使用dbutils能极大简化jdbc编码的工作量，同时也不会影响程序的性能。因此dbutils成为很多不喜欢hibernate的公司的首选。
#http://www.cnblogs.com/xdp-gacl/p/4007225.html
  
  
########## 4. allydata crawler config value ###########
########## 4.1 test config value ###########
zookeeper.connect=10.1.11.44:2181/dmp/spider_kafka

#selector
curatorconnect=10.1.11.44:2181
curatornamespace=allydatacrawlersystem
 
from.template.topic=tpl_topic
to.schedule.topic=schedule_topic

#schedule
topic.names=scheduleT1,sheduleT2,sheduleT3
 
#Create a topic
bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic tpl_topic
bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic schedule_topic
bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic scheduleT1,sheduleT2,sheduleT3


########## 4.2 tomcat cmd ###########
./bin/shutdown.sh 
./bin/startup.sh 

admin admin-tomcat-pwd

########## 4.2 tomcat log ###########
1.Cataline引擎的日志文件，文件名catalina.日期.log
2.Tomcat下内部代码丢出的日志，文件名localhost.日期.log（jsp页面内部错误的异常，org.apache.jasper.runtime.HttpJspBase.service类丢出的，日志信息就在该文件！）
3.Tomcat下默认manager应用日志，文件名manager.日期.log 
4.控制台输出的日志，Linux下默认重定向到catalina.out 







