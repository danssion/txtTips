######## 0.env ##########
groupadd kafka
useradd -g kafka kafka
usermod -g kafka kafka

mkdir -p /opt/modules
chown kafka:root /opt/modules

##### 0.1 hosts #####
192.168.200.214 zk1
192.168.200.215 zk2
192.168.200.216 zk3
192.168.200.217 zk4
192.168.200.218 zk5


##### 0.2 profile #####


######## 1.jdk ############
ln -s jdk1.7.0_21/ jdk


######## 2.zookeeper ###########
wget http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz 
tar zxf zookeeper-3.4.6.tar.gz
mv zookeeper-3.4.6  /opt/modules/
cd /opt/modules
ln -s zookeeper-3.4.6  zookeeper

mkdir -p /opt/data/zookeeper/data
mkdir -p /opt/data/zookeeper/datalog
echo [1/2/3/4/5] > /opt/data/zookeeper/data/myid
chown kafka:kafka -R /opt/data/zookeeper

cd /opt/modules/zookeeper/conf
cp zoo_sample.cfg zoo.cfg

## edit zoo.cfg
dataDir=/opt/data/zookeeper/data
clientPort=2181
initLimit=10
syncLimit=5
tickTime=2000
dataLogDir=/opt/data/zookeeper/datalog

server.1=zk1:2888:3888
server.2=zk2:2888:3888
server.3=zk3:2888:3888
server.4=zk4:2888:3888
server.5=zk5:2888:3888

## manage zookeeper
zkServer.sh {start|start-foreground|stop|restart|status|upgrade|print-cmd}



######## 2.kafka ###########
mkdir -p /opt/data/kafka/log
chown kafka:kafka -R /opt/data/kafka

######## 2.0 kafka install ###########
curl -s https://get.sdkman.io | bash
#open new terminal
source "/root/.sdkman/bin/sdkman-init.sh"
bin/kafka-server-start.sh config/server.properties
sdk install gradle 3.1
#cd  kafka dir
gradle

###### 2.1 server.properties ######
broker.id=[1/2/3/4/5]
log.dirs=/tmp/kafka-logs
num.partitions=1
zookeeper.connect=localhost:2181
zookeeper.connection.timeout.ms=6000



###### 2.2 kafka cmd ######
#start server
bin/kafka-server-start.sh config/server.properties
bin/kafka-server-start.sh -daemon config/server.properties

#broken
#下线broker  
./kafka-run-class.sh kafka.admin.ShutdownBroker --zookeeper 127.0.0.1:2181 --broker datanode1 --num.retries 3 --retry.interval.ms 60  
#broker list
zk_home/ bin / zkCli.sh 执行ls /brokers/ids 就可以看到zk中存的所有的broker id list

#
#Create a topic
bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 4 --topic testT
kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 4 --topic applogsend
#delete
./kafka-run-class.sh kafka.admin.DeleteTopicCommand --topic applogsend --zookeeper namenode:2181 

# list topic 
./bin/kafka-topics.sh --list --zookeeper localhost:2181
./bin/kafka-topics.sh --list --zookeeper 172.16.5.1:2181,172.16.5.2:2181,172.16.5.3:2181
kafka-topics.sh --describe --zookeeper namenode:2181
### topic info
./bin/kafka-topics.sh  --describe --zookeeper 172.16.5.1:2181,172.16.5.2:2181,172.16.5.3:2181 --topic mt_tickers
./bin/kafka-topics.sh  --describe --zookeeper 172.16.5.1:2181,172.16.5.2:2181,172.16.5.3:2181 --topic transfer_info_push_data
./bin/kafka-console-consumer.sh --bootstrap-server 172.16.5.1:9092,172.16.5.2:9092,172.16.5.3:9092 --topic mt_price_log --from-beginning


#Send some messages
bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
bin/kafka-console-producer.sh --broker-list localhost:9092 --topic applogsend
bin/kafka-console-producer.sh --broker-list datanode1:9092 --topic applogsend

#Start a consumer
bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning
bin/kafka-console-consumer.sh -zookeeper localhost:2181 --from-beginning --topic applogsend
### message in topic
./bin/kafka-console-consumer.sh --bootstrap-server 172.16.5.1:9092,172.16.5.2:9092,172.16.5.3:9092 --topic mt_price_log --from-beginning
kafka-console-consumer --bootstrap-server localhost:9092 --topic tickers --from-beginning
#aliyun kafka
kafka-console-consumer --bootstrap-server 172.17.1.86:9092,172.17.1.87:9092,172.17.1.88:9092  --topic test --group test_group --from-beginning
./bin/kafka-console-consumer.sh --bootstrap-server 172.16.5.1:9092,172.16.5.2:9092,172.16.5.3:9092 --topic test01 --group transfer_info_push_data --from-beginning

### consumer group info
./bin/kafka-consumer-groups.sh --bootstrap-server 172.16.5.1:9092,172.16.5.2:9092,172.16.5.3:9092 --describe  --group getui_transfer 
#ecs kafka
./bin/kafka-consumer-groups.sh --describe --bootstrap-server 172.16.5.1:9092,172.16.5.2:9092,172.16.5.3:9092 --group mt_global_trend
./bin/kafka-consumer-groups.sh --describe --bootstrap-server 172.16.5.1:9092,172.16.5.2:9092,172.16.5.3:9092 --group tickers/default
#消费组消费情况
./bin/kafka-consumer-groups.sh --describe --bootstrap-server 172.16.5.1:9092,172.16.5.2:9092,172.16.5.3:9092 --group websocket-group
## --members 此选项提供使用者组中所有活动成员的列表
# --verbose 这个选项还提供了分配给每个成员的分区。
# --state  这个选项提供了有用的组级信息


#
#consumer list
./bin/kafka-consumer-groups.sh --bootstrap-server 172.16.5.1:9092,172.16.5.2:9092,172.16.5.3:9092 --list 
./bin/kafka-consumer-groups.sh --new-consumer --bootstrap-server localhost:9092 --list
./bin/kafka-consumer-groups.sh --new-consumer --bootstrap-server 172.16.5.1:9092,172.16.5.2:9092,172.16.5.3:9092 --list

### consumer info
./bin/kafka-consumer-groups.sh --new-consumer --bootstrap-server localhost:9092 --group shipper --describe
./bin/kafka-consumer-groups.sh --new-consumer --bootstrap-server 172.16.5.1:9092,172.16.5.2:9092,172.16.5.3:9092 --group getui_transfer --describe
######## 3.kafka conf ###########
https://kafka.apache.org/documentation/

##### 3.1 consumer conf #####
https://kafka.apache.org/documentation/#consumerconfigs



