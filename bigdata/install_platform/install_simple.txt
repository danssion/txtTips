#######################################################################
#					安装data和yarn节点							#
#				安装客户端不同处以字母A为序号						#
#######################################################################

#################### 1.0 用户添加 ####################
groupadd hadoop
useradd -g hadoop hadoop
usermod -G hadoop hadoop
usermod -G dev hadoop
usermod -G hadoop duanxiang

#################### 1.1 hadoop client 免登录ssh ####################
cd /home/hadoop
mkdir .ssh
touch .ssh/authorized_keys
vi .ssh/authorized_keys
拷贝 50 中 id_rsa.pub 到文件 authorized_keys
ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEA4qOtfjeLkm0ynphEbtngn7KyDd77OeNXQ0OQHzn/8v4C+TlA89XZ5dRSLBCzF/3+04rB3G7YND4oc0SBjjd6CregUIEzq88kuo0dn2rY9RlN/kcguqTJ3giqlHlvYU0nbFSi5xDCMNPbIce7exGXOb0puScieBKdMjRPM3VMjSEOA5SPxxodUgogboCvhmbOgrpLqeXMi3VJZGckXd814sLE5sPN6TaQRAxNGZrxLoxWLNG2x4/qOwWADENptYsykwx1X/aCIXChfdJ9ehS5XnwC6wcSt/9Gkfwwx7CEg3dGi9BU/JILaW6Qqd5jIYvja/rsOK5g50RkHwAb3xAYOQ== hadoop@BFG-OSER-2372
chmod 700 -R .ssh/
chown hadoop:hadoop -R .ssh/

#################### 1.2 hadoop 目录准备 ####################
DATA_PATH=/opt/data
mkdir -p $DATA_PATH/hadoop/temp $DATA_PATH/hadoop/data $DATA_PATH/hadoop/namenode
mkdir -p /data1/data/hadoop/mapred/local  /data1/data/hadoop/mapred/system
mkdir -p /data2/data/hadoop/data /opt/data/hadoop/data  /data1/data/hadoop/data
(依据服务器 或 mkdir -p /opt/data/hadoop/data /data2/data/hadoop/data /data3/data/hadoop/data  /data1/data/hadoop/data)
mkdir -p $DATA_PATH/hadoop/jn
mkdir -p $DATA_PATH/namenode/ /data1/data/hadoop/namenode
chown -R hadoop:hadoop $DATA_PATH/hadoop $DATA_PATH/namenode/
chown -R hadoop:hadoop /data1/data/hadoop /data2/data/hadoop  /opt/data/hadoop
(依据服务器 或 chown -R hadoop:hadoop /opt/data/hadoop/ /data1/data/hadoop /data2/data/hadoop  /data3/data/hadoop )

#################### 1.2A hadoop 目录准备(获取log的client 端) ###################
DATA_PATH=/data1
mkdir -p $DATA_PATH/data/logdata
chown -R rsync:rsync $DATA_PATH/data/
chmod 0775 $DATA_PATH/data/

DATA_PATH=/opt/data
mkdir -p $DATA_PATH/hadoop/temp
chown -R hadoop:hadoop $DATA_PATH/hadoop 

mkdir -p /opt/baofeng-data/windforce-shell
chown hadoop:hadoop /opt/baofeng-data/windforce-shell


#################### 1.3 host 目录准备 ######################
#依据不同服务器有不同配置各个服务器需要更新

[114.112.82.141]   dNodeHttp  nodeMHttp
192.168.1.54     BFG-OSER-1016.localdomain BFG-OSER-1016
192.168.1.53     20150416-53.localdomain 20150416-53
192.168.1.52     BFG-OSER-2374.localdomain BFG-OSER-2374
192.168.1.51     BFG-OSER-2373.localdomain BFG-OSER-2373
192.168.1.50     BFG-OSER-2372.localdomain BFG-OSER-2372
192.168.1.36     BFG-OSER-924.localdomain BFG-OSER-924
192.168.1.37     BFG-OSER-923.localdomain BFG-OSER-923
192.168.2.141   BFG-OSER-900.localdomain BFG-OSER-900
192.168.2.142   BFG-OSER-1345.localdomain BFG-OSER-1345
192.168.2.176   BFG-OSER-2367.localdomain BFG-OSER-2367
192.168.2.177   BFG-OSER-2368.localdomain BFG-OSER-2368
192.168.2.178   BFG-OSER-2369.localdomain BFG-OSER-2369
192.168.2.179   BFG-OSER-2370.localdomain BFG-OSER-2370
192.168.2.113	Online-82-113.localdomain Online-82-113
192.168.2.114	Online-82-114.localdomain Online-82-114

114.112.70.50 resourceOut
192.168.1.50 resourceM
192.168.1.50 zoo1 qjournal1 jobhistory hdcluster nn1
192.168.1.51 zoo2 qjournal2 nn2 datanode4
192.168.1.52 zoo3 qjournal3 datanode1
192.168.1.53 datanode2
192.168.1.54 datanode3
192.168.2.141 datanode5
192.168.2.142 datanode6
192.168.2.176 datanode7
192.168.2.177 datanode8
192.168.2.178 datanode9
192.168.2.179 datanode10
192.168.2.113 datanode11
192.168.2.114 datanode12
192.168.1.36 datanode13
192.168.1.37 datanode14
192.168.1.49 hiveclient

#################### 系统环境 1.4 ####################
#ulimit -a 查看max user processes              (-u) unlimited
#有限制进行下面的操作
#
echo "100000" > /proc/sys/kernel/threads-max
ulimit -u unlimited
ulimit -a
#设置在/etc/security/limits.conf文件中 
vi /etc/security/limits.conf
hadoop   - nproc  1024000

#################### 软件环境 2.0 ####################
软件包由 50 服务器推送到相关目录下
mkdir /opt/modules
chown hadoop:hadoop /opt/modules
python
hadoop
lzo相关
java

#################### 软件环境 2.0 (client) ####################
软件包由 50 服务器推送到相关目录下
mkdir /opt/modules
chown hadoop:hadoop /opt/modules
python
hadoop
lzo相关
mysql
hive
java

#################### java 软件环境 2.1 ####################
su hadoop
tar zxf jdk-7u15-linux-x64.tar.gz
ln -s jdk1.7.0_15 jdk

#################### lzo 软件环境 2.2 ####################
##安装lzo
wget http://apt.sw.be/redhat/el5/en/x86_64/rpmforge/RPMS/lzo-devel-2.06-1.el5.rf.x86_64.rpm
wget http://apt.sw.be/redhat/el5/en/x86_64/rpmforge/RPMS/lzo-2.06-1.el5.rf.x86_64.rpm
	
rpm -ivh lzo-2.06-1.el5.rf.x86_64.rpm
rpm -ivh lzo-devel-2.06-1.el5.rf.x86_64.rpm

##安装lzop-1.03.tar.gz
tar zxvf lzop-1.03.tar.gz
cd lzop-1.03
./configure
make
make install

#有编译的hadoop版本可忽略
##hadoop-lzo-0.4.20-SNAPSHOT.jar
#来源https://github.com/twitter/hadoop-lzo/
wget https://github.com/twitter/hadoop-lzo/archive/master.zip
unzip master
#更新hadoop-lzo中的pom.xml
<properties>
    <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
    <hadoop.current.version>2.2.0</hadoop.current.version>
    <hadoop.old.version>1.0.4</hadoop.old.version>
  </properties>
export CFLAGS=-m64
export CXXFLAGS=-m64
mvn clean package -Dmaven.test.skip=true
cd target/native/Linux-amd64-64
tar -cBf - -C lib . | tar -xBvf - -C ./
cp ./libgplcompression* /opt/modules/hadoop-2.*/lib/native/
cp target/hadoop-lzo-0.4.20-SNAPSHOT.jar /opt/modules/hadoop-2.*/share/hadoop/common/


#################### python 软件环境 2.3 ####################
cd /opt/modules/
mv /home/hadoop/python2.7.8.tar.gz ./
tar zxvf python2.7.8.tar.gz
ln -s /opt/modules/python2.7.8 python

#变更yum使用的python版本
vi /usr/bin/yum
#!/usr/bin/python  -->  #!/usr/bin/python2.4
#!/usr/bin/python  -->  #!/usr/bin/python2.6

#更新python版本
cd /usr/bin
mv python python_old
ln -s /opt/modules/python/bin/python python


#################### zookeeper 软件环境 2.4 ####################
安装 zookeeper
curl -O http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz
tar zxvf zookeeper-3.4.6.tar.gz -C /opt/modules
cd /opt/modules/zookeeper-3.4.6/conf
cp zoo_sample.cfg zoo.cfg
#准备目录
DATA_PATH=/data/data
mkdir -p $DATA_PATH/zookeeper/data
mkdir -p $DATA_PATH/log/zookeeper/
chmod -R 0777 $DATA_PATH/log
chmod -R 774 /opt/modules/zookeeper
chmod -R 775 /opt/modules/zookeeper/bin
#加入机器id,按照配置中的写(每个节点都要有)
#按照配置的id写
echo '1' > $DATA_PATH/zookeeper/data/myid
ln -s /opt/modules/zookeeper-3.4.5 /opt/modules/zookeeper

chown hadoop:hadoop -R /data/data /opt/modules/
#编辑zookeeper配置文件
vim zoo.cfg
	修改dataDir的值为/data/data/zookeeper/data
	在末尾加入
	server.1=zoo1:2888:3888
	server.2=zoo2:2888:3888
	server.3=zoo3:2888:3888
:wq

vim log4j.properties
zookeeper.log.dir=/data/data/log/zookeeper

#启动
./bin/zkServer.sh start

#################### hadoop 编译环境 2.4 ####################
#protoc 
yum install  protobuf-compiler.x86_64
yum install cmake.x86_64

#################### hadoop 编译 2.5.0 ####################
#有编译的版本可忽略
#下载版本解压
cd hadoop-2.6.*-src
mvn package -X -Pdist,native,src -DskipTests -Dtar



#################### hadoop 软件环境 2.5.1 ####################
cd /opt/modules
tar zxf hadoop-20150328-2.6.0.tar.gz
ln -s hadoop-2.6.0/ hadoop

#检查/opt/modules/hadoop/etc/是否包含3个配置目录hadoop-ordinary  hadoop-141-142  hadoop-113-114
#从50分发配置到各个服务器

#变更配置文件 141 142 53 54 36 37 机器
cd /opt/modules/hadoop/etc
rm hadoop
ln -s hadoop-141-142 hadoop
#变更配置文件 113 114 机器
cd /opt/modules/hadoop/etc
rm hadoop
ln -s hadoop-113-114 hadoop
#其他使用默认

#################### hadoop 软件环境 2.5.1A ####################
cd /opt/modules
tar zxf hadoop.tar.gz
ln -s hadoop-2.0.0-cdh4.6.0/ hadoop


#################### hadoop native lib环境 2.5.2（可选） ####################
#/lib64/libc-2.*.so  版本低于 2.9  需要安装
mkdir gblic
cd gblic
wget  http://ftp.gnu.org/gnu/glibc/glibc-2.9.tar.bz2 ./
wget http://ftp.gnu.org/gnu/glibc/glibc-linuxthreads-2.5.tar.bz2 ./
tar -jxvf glibc-2.9.tar.bz2
cd glibc-2.9
tar -jxvf ../glibc-linuxthreads-2.5.tar.bz2
cd ..
./glibc-2.9/configure --prefix=/usr --disable-profile --enable-add-ons --with-headers=/usr/include --with-binutils=/usr/bin
make
make install



#################### shell 环境 2.6 ####################
cd /opt/modules
ln -s /opt/modules/jdk1.7.0_15/ jdk
#配置 /etc/profile
vim /etc/profile (加入以下内容)

export PATH
export JAVA_HOME=/opt/modules/jdk
export HADOOP_HOME=/opt/modules/hadoop
export PYTHON_HOME=/opt/modules/python
#如需要zookeeper
#把zookeeper路径加入环境变量/etc/profile
export ZOOKEEPER_HOME=/opt/modules/zookeeper
export PATH=$PATH:$ZOOKEEPER_HOME:$ZOOKEEPER_HOME/bin

export PATH=$PATH:$HADOOP_HOME:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PYTHON_HOME/bin



#################### shell 环境 2.6(client) ####################
#配置 /etc/profile
vim /etc/profile (加入以下内容)

export PATH
export JAVA_HOME=/opt/modules/jdk
export HADOOP_HOME=/opt/modules/hadoop
export PYTHON_HOME=/opt/modules/python
export MYSQL_HOME=/opt/modules/mysql
export PATH=$PATH:$HADOOP_HOME:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PYTHON_HOME/bin:$MYSQL_HOME/bin











